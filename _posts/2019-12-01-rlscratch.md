---
title: 'RL Algorithms from Scratch'
layout: post
toc: false
comments: true
hide: true
search_exclude: true
---

This project follows from advice on [Spinning Up as Deep RL Researcher](https://spinningup.openai.com/en/latest/spinningup/spinningup.html).
I started by building my fundamentals in mathematics, deep learning and reinforcement learning. I studied the Deep Learning book and then followed it with David Silver's and Sergey Levine's course on Deep RL.

As I learned about different algorithms, I read their original papers and started reproducing them in Tensorflow and PyTorch code. Here are some of the algorithms I implemented:

 - Deep Q-Network: [[ code ]](https://github.com/shakti365/dqn)

 - Policy Gradient (REINFORCE): [[ code ]](https://github.com/shakti365/vpg)

 - Asynchronous Advantage Actor-Critic: [[ code ]](https://github.com/shakti365/a3c) [[ notes ]]({{site.baseurl}}/rl/2020/04/25/a3c.html)

 - Proximal Policy Gradient: [[ code ]](https://github.com/shakti365/ppo) [[ notes ]]({{site.baseurl}}/rl/2020/06/15/ppo.html)

 - Soft Actor-Critic: [[ code ]](https://github.com/shakti365/sac) [[ notes ]]({{site.baseurl}}/rl/2020/01/01/sac.html) 
